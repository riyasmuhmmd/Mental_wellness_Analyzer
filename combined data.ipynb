{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RasfvxnNoRL5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the dataset\n",
        "data = pd.read_csv('/content/Combined Data.csv')\n",
        "data = data.dropna(subset=['statement'])\n"
      ],
      "metadata": {
        "id": "bjHEaBZ3yLCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
        "    text = re.sub(r'\\d+|\\W+', ' ', text)  # Remove special characters, numbers, punctuations\n",
        "    return text.lower()  # Convert to lowercase\n",
        "    data['statement'] = data['statement'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "Jk1pLVe_zVZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = data['statement']\n",
        "y = data['status']\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "azVa8PHLyQJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n"
      ],
      "metadata": {
        "id": "AiNQCObUyUuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize the text data\n",
        "max_vocab_size = 10000  # Reduced vocab size\n",
        "max_sequence_length = 100  # Reduced sequence length\n",
        "tokenizer = Tokenizer(num_words=max_vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "np7IllQ7yeC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "# Pad the sequences\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# Tokenize and pad the test data as well\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test) #Tokenize X_test and store the result in X_test_seq\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "HbhNQORzyhh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert target labels to categorical\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_train_categorical = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "-q41Mt-gyllq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = {i: class_weights[i] for i in range(num_classes)}\n"
      ],
      "metadata": {
        "id": "Eiona9B9yogH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the optimized LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_vocab_size, output_dim=100, input_length=max_sequence_length),  # Reduced embedding dim\n",
        "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),  # Single LSTM layer\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for faster training\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5)\n",
        "\n",
        "# Train the model\n",
        "Train = model.fit(\n",
        "    X_train_padded,\n",
        "    y_train_categorical,\n",
        "    epochs=15,\n",
        "    batch_size=128,  # Larger batch size\n",
        "    validation_data=(X_test_padded, y_test_categorical),\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQQrQnhTyrUc",
        "outputId": "b8364a1a-c59c-4731-a8b6-7972febdac2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - accuracy: 0.3413 - loss: 1.8323 - val_accuracy: 0.3341 - val_loss: 1.5245 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 188ms/step - accuracy: 0.3649 - loss: 1.6982 - val_accuracy: 0.5332 - val_loss: 1.3189 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 188ms/step - accuracy: 0.4994 - loss: 1.4949 - val_accuracy: 0.5398 - val_loss: 1.0336 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 184ms/step - accuracy: 0.5549 - loss: 1.2745 - val_accuracy: 0.5938 - val_loss: 0.9017 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 188ms/step - accuracy: 0.6097 - loss: 1.0472 - val_accuracy: 0.6006 - val_loss: 0.8662 - learning_rate: 0.0010\n",
            "Epoch 6/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 192ms/step - accuracy: 0.6335 - loss: 0.8376 - val_accuracy: 0.6344 - val_loss: 0.8294 - learning_rate: 0.0010\n",
            "Epoch 7/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 185ms/step - accuracy: 0.6652 - loss: 0.6775 - val_accuracy: 0.6537 - val_loss: 0.7836 - learning_rate: 0.0010\n",
            "Epoch 8/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 189ms/step - accuracy: 0.6959 - loss: 0.5470 - val_accuracy: 0.6772 - val_loss: 0.7432 - learning_rate: 0.0010\n",
            "Epoch 9/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 194ms/step - accuracy: 0.7268 - loss: 0.4759 - val_accuracy: 0.7032 - val_loss: 0.7218 - learning_rate: 0.0010\n",
            "Epoch 10/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 187ms/step - accuracy: 0.7684 - loss: 0.4031 - val_accuracy: 0.7179 - val_loss: 0.6987 - learning_rate: 0.0010\n",
            "Epoch 11/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 190ms/step - accuracy: 0.7888 - loss: 0.3588 - val_accuracy: 0.7269 - val_loss: 0.7355 - learning_rate: 0.0010\n",
            "Epoch 12/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 189ms/step - accuracy: 0.7979 - loss: 0.3306 - val_accuracy: 0.7196 - val_loss: 0.7713 - learning_rate: 0.0010\n",
            "Epoch 13/15\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 188ms/step - accuracy: 0.8192 - loss: 0.2883 - val_accuracy: 0.7359 - val_loss: 0.7333 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test_categorical)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "ekwV0_c6y3bI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91bd5a6a-c7d3-4e54-9cde-07ab66252126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 46ms/step - accuracy: 0.7173 - loss: 0.6884\n",
            "Test Accuracy: 71.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(X_test_padded)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "KE7OxEB8y97D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4474b58a-93e7-420b-dd0f-06d43ab03cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "             Anxiety       0.79      0.77      0.78       768\n",
            "             Bipolar       0.79      0.79      0.79       556\n",
            "          Depression       0.79      0.41      0.54      3081\n",
            "              Normal       0.94      0.90      0.92      3269\n",
            "Personality disorder       0.51      0.69      0.59       215\n",
            "              Stress       0.47      0.75      0.57       517\n",
            "            Suicidal       0.53      0.83      0.65      2131\n",
            "\n",
            "            accuracy                           0.72     10537\n",
            "           macro avg       0.69      0.74      0.69     10537\n",
            "        weighted avg       0.76      0.72      0.71     10537\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the model and tokenizer\n",
        "model.save('optimized_lstm_text_classifier.h5')\n",
        "import pickle\n",
        "with open('optimized_tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n"
      ],
      "metadata": {
        "id": "NTaRUTcIy7Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" Self Massage for Stress Relief: 4 Relaxation Techniques to Try Stress levels are on the rise. 84% of Americans feel stressed at least one day a week. With financial \"\n",
        "# Use preprocess_text instead of clean_text\n",
        "text = preprocess_text(text)\n",
        "# Use tokenizer instead of vectorizer\n",
        "text_seq = tokenizer.texts_to_sequences([text])\n",
        "text_padded = pad_sequences(text_seq, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# Predict using the Keras model\n",
        "sentiment_probs = model.predict(text_padded)\n",
        "predicted_label_index = np.argmax(sentiment_probs, axis=1)\n",
        "\n",
        "sentiment_label = label_encoder.inverse_transform(predicted_label_index)\n",
        "print(f'Predicted Sentiment: {sentiment_label[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm9s-H7XCDsy",
        "outputId": "df148d05-c3a4-44a5-809c-a35049caee7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "Predicted Sentiment: Stress\n"
          ]
        }
      ]
    }
  ]
}